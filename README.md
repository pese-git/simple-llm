# Simple-LLM Framework

[![Python Version](https://img.shields.io/badge/python-3.8%2B-blue)]()
[![PyTorch Version](https://img.shields.io/badge/pytorch-1.10%2B-orange)]()

–ü—Ä–æ—Å—Ç–∞—è –∏ –ø–æ–Ω—è—Ç–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏ GPT-—Å—Ç–∏–ª—è —Å –Ω—É–ª—è –Ω–∞ PyTorch

## üîç –û–±–∑–æ—Ä

Simple-LLM –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç:
- –ü–æ–ª–Ω—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã GPT
- –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä BPE
- –ú–æ–¥—É–ª–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ (–≤–Ω–∏–º–∞–Ω–∏–µ, FFN, —ç–º–±–µ–¥–¥–∏–Ω–≥–∏)
- –ì–∏–±–∫—É—é —Å–∏—Å—Ç–µ–º—É –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞
- –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
```bash
pip install torch numpy tqdm
```

2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø—Ä–∏–º–µ—Ä—ã:
```bash
# –ü—Ä–∏–º–µ—Ä –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞
python example/example_gpt.py

# –ü—Ä–∏–º–µ—Ä –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
python example/train_gpt_example.py
```

## üß† –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

### –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
```python
from simple_llm.data.get_data import GetData

dataset = GetData(
    data=[1, 2, 3, 4, 5],  # –í—Ö–æ–¥–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
    seq_len=3,             # –î–ª–∏–Ω–∞ –æ–∫–Ω–∞
    device="cuda"          # –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
)
```

### –ú–æ–¥–µ–ª—å GPT
```python
from simple_llm.transformer.gpt import GPT

model = GPT(
    vocab_size=10000,
    max_seq_len=512,
    emb_size=768,
    num_heads=12,
    num_layers=6
)
```

### –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
```python
output = model.generate(
    input_ids,
    max_new_tokens=100,
    temperature=0.9,
    top_k=50,
    top_p=0.9
)
```

### –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
```python
from torch.utils.data import DataLoader

# –î–∞–Ω–Ω—ã–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ (input_ids, targets)
# targets - —ç—Ç–æ input_ids, —Å–¥–≤–∏–Ω—É—Ç—ã–µ –Ω–∞ 1 —Ç–æ–∫–µ–Ω –≤–ø–µ—Ä–µ–¥
train_loader = DataLoader(...) 

model.fit(
    train_loader=train_loader,  # –û–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)
    valid_loader=None,          # –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    num_epoch=10,               # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
    learning_rate=0.001         # –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
)

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
model.save("model.pt")

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
loaded_model = GPT.load("model.pt", device="cuda")
```

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –¥–∞–Ω–Ω—ã–º:**
- –§–æ—Ä–º–∞—Ç: `(input_ids, targets)` –≥–¥–µ `targets = roll(input_ids, -1)`
- `input_ids`: —Ç–µ–Ω–∑–æ—Ä —Ñ–æ—Ä–º—ã `[batch_size, seq_len]`
- –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –∫–∞–∫ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ, —Ç–∞–∫ –∏ —Ä–µ–∞–ª—å–Ω—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ

## üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

–ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –¥–æ—Å—Ç—É–ø–Ω–∞ –≤ [doc/](./doc/):
- [–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ GPT](./doc/gpt_documentation_ru.md)
- [–ê–ª–≥–æ—Ä–∏—Ç–º BPE](./doc/bpe_algorithm.md)
- [–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π](./doc/get_data_documentation_ru.md)
- [–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è](./example/)

## üõ† –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
```bash
pytest tests/
```

## ü§ù –ö–∞–∫ –≤–Ω–µ—Å—Ç–∏ –≤–∫–ª–∞–¥
1. –§–æ—Ä–∫–Ω–∏—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
2. –°–æ–∑–¥–∞–π—Ç–µ –≤–µ—Ç–∫—É (`git checkout -b feature/AmazingFeature`)
3. –°–¥–µ–ª–∞–π—Ç–µ –∫–æ–º–º–∏—Ç (`git commit -m 'Add some AmazingFeature'`)
4. –ó–∞–ø—É—à—å—Ç–µ –≤–µ—Ç–∫—É (`git push origin feature/AmazingFeature`)
5. –û—Ç–∫—Ä–æ–π—Ç–µ Pull Request

## üìú –õ–∏—Ü–µ–Ω–∑–∏—è
–†–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è–µ—Ç—Å—è –ø–æ–¥ –ª–∏—Ü–µ–Ω–∑–∏–µ–π MIT. –°–º. [LICENSE](./LICENSE)

# Эволюция моделей GPT (GPT-1 → GPT-4.1): гиперпараметры, оборудование, возможности и источники

## 1. Гиперпараметры моделей

| Модель    | Параметры | Слои | Hidden Size | Heads | Контекст | Объем данных | Примечания        |
|-----------|-----------|------|--------------|--------|----------|---------------|-------------------|
| GPT-1     | 117M      | 12   | 768          | 12     | 512      | ~5GB          | BooksCorpus    |
| GPT-2 S   | 117M      | 12   | 768          | 12     | 1,024    | ~40GB         | WebText        |
| GPT-2 M   | 345M      | 24   | 1,024        | 16     | 1,024    | не указано    |                   |
| GPT-2 L   | 762M      | 36   | 1,280        | 20     | 1,024    | не указано    |                   |
| GPT-2 XL  | 1.5B      | 48   | 1,600        | 25     | 1,024    | не указано    |                   |
| GPT-3     | 175B      | 96   | 12,288       | 96     | 2,048    | ~300B токенов | Few-shot SOTA  |
| GPT-3.5   | ≈175B     | ?    | ?            | ?      | 4K–8K    | не раскрыто   | RLHF              |
| GPT-4     | ?         | ?    | ?            | ?      | 8K–32K   | не раскрыто   | Multimodal     |
| GPT-4.1   | ?         | ?    | ?            | ?      | до 128K  | не раскрыто   | GPT-4-turbo    |

**Примечания:**
- Для GPT-2 существуют несколько версий с разным числом параметров и архитектурой.
- Для GPT-3.5 и GPT-4 официальные архитектурные детали не раскрывались полностью; часть данных основана на аналитических обзорах и оценках.

## 2. Оборудование для обучения

| Модель   | ГПУ            | Объем памяти | Кол-во GPU  | Инфраструктура         | Оценка стоимости   |
|----------|----------------|--------------|-------------|------------------------|--------------------|
| GPT-1    | V100 (?)       | 16GB         | 1–4         | локально               | -                  |
| GPT-2    | V100           | 16GB         | до 256      | кластер                | ~$50K–100K         |
| GPT-3    | V100 (Azure)   | 16GB         | ~1K–3K      | Azure Supercomputer    | ~$4.6 млн       |
| GPT-3.5  | A100 (Azure)   | 40–80GB      | ~5K+        | Azure AI               | >$10M (оценка)     |
| GPT-4    | A100 (Azure)   | 80GB         | 25K–30K     | Azure AI SuperCluster  | >$50–100 млн    |
| GPT-4.1  | A100/H100 (?)  | 80–96GB      | ~30K+       | Azure + оптимизация    | не раскрыто        |

**Примечания:**
- Для GPT-1 и GPT-2 использовались NVIDIA V100, для GPT-3 и старше — масштабируемые распределённые кластеры Azure с тысячами GPU.
- Аппаратные параметры для новых моделей основаны на независимых разборах индустриальных аналитиков и публикациях.

## 3. Возможности моделей

| Модель   | Генерация текста | Логика/рассуждения | Программирование | Работа с изображениями | Контекст | Особенности              |
|----------|------------------|---------------------|------------------|------------------------|----------|--------------------------|
| GPT-1    | 🟡               | 🔴                  | 🔴               | 🔴                     | 512      | Дообучение на задачах    |
| GPT-2    | 🟢               | 🟡                  | 🟡               | 🔴                     | 1,024    | Few-shot появилось       |
| GPT-3    | 🟢🟢             | 🟡                  | 🟡               | 🔴                     | 2,048    | Few-shot на практике     |
| GPT-3.5  | 🟢🟢             | 🟢                  | 🟢               | 🔴                     | 4K–8K    | RLHF, ChatGPT            |
| GPT-4    | 🟢🟢🟢           | 🟢🟢                | 🟢🟢             | 🟢                     | 8K–32K   | Multimodal, точность     |
| GPT-4.1  | 🟢🟢🟢           | 🟢🟢🟢              | 🟢🟢🟢           | 🟢                     | до 128K  | Быстрее и дешевле     |

**Условные обозначения:**  
🟡 — ограниченно, 🟢 — хорошо, 🟢🟢 — очень хорошо, 🟢🟢🟢 — выдающийся уровень, 🔴 — не поддерживается

## 4. Уникальные особенности поколений

- **GPT-1**: Показал возможность предобучения на корпусе «сырых» текстов.
- **GPT-2**: Сильная генерация длинных текстов, дискуссия о рисках, delayed release самой крупной модели.
- **GPT-3**: Прорыв в few-shot обучении, широкий спектр заданий без дополнительной настройки, мощные API.
- **GPT-3.5**: Инфраструктурная фаза (ChatGPT, RLHF), уверенное выполнение инструкций и написание кода.
- **GPT-4**: Мультимодальность (текст+изображения), большой контекст, существенно улучшена точность и безопасность.
- **GPT-4.1**: Расширение по скорости, стоимости, надежности, до 128K токенов, улучшенный inference.

## 5. Источники

1. GPT-1: Radford et al., 2018, “Improving Language Understanding by Generative Pre-Training”.
2. GPT-2: OpenAI, “Better Language Models and Their Implications”.
3. GPT-3: Brown et al., 2020, “Language Models are Few-Shot Learners”.
4. GPT-4: OpenAI, “GPT-4 Technical Report”.
5. Независимый анализ: SemiAnalysis, EleutherAI, Hugging Face (обзорные публикации и сравнения с оценками аппаратных характеристик и стоимости).
